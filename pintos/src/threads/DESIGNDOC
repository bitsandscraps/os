			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jongeui Park <qkrwhddml@kaist.ac.kr>
Seongsu Cho  <csp00141@kaist.ac.kr>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

At first we did not know that even the first assignment will require us
to make new data structures and functions. We tried to find a way to
manage it without creating new things, which we failed, and googled for
a solution. We found the following blog:
http://maplejune.tistory.com/entry/Pintos-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-1-Alarm-Clock
After finishing the first part by the help from the blog, we realized
that we should never be afraid of creating new things.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

waiting_list is a list of processes that are sleeping.

static struct list waiting_list;

Added to struct thread:

    int64_t wakeup_tick;                /* Timer tick to wake up. */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When timer_sleep is called, the timer tick that it should wake up
is calculated. Storing that wakeup_tick information, the thread is
moved to the waiting_list. Then, thread_block() is called.

The timer interrupt handler searches for threads that should be
awakened and unblocks those threads using thread_unblock().

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The waiting_list is always sorted in the order of wakeup_tick.
If the interrupt handler finds out that the current element on the
list should not yet be awakened, it may just end traversing the list.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We just disabled the interrupt. The kernel does not context switch
during the call to timer_sleep().

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We just disabled the interrupt. Timer interrupt cannot happen during
the call to timer_sleep().

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int initial_priority;         /* Initial priority. */
    /* Lock that the thread is trying to acquire. */
    struct lock * lock_trying_acquire;
    struct list locks_holding;    /* Locks the thread is holding. */

Added to struct lock:

    int priority;                 /* Most recent priority donation. */
    struct list_elem elem;        /* List element. Managed in struct thread. */

Added to struct semaphore_elem:

    int priority;                 /* Priority of thread waiting. */


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The sema_up () function awakens the thread with the highest priority
using the list_max () function on its waiters list. To ensure that
that the running thread should always be the one with the highest
priority, the function compares the priority of the current thread
and the newly unblocked thread. If the new thread has higher priority
the current thread will yield to the new one.

Since each lock uses a single semaphore, highest priority awakens first
rule is automatically applied to locks. For conditional variables,
though, this is not the case. Conditional variables assign different
semaphores to different threads. 


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Suppose Thread 0 with priority 30 is holding lock A. It is trying to set
its priority to be 20. Before the setting is finished, here comes
Thread 1 with priority 40. It tries to acquire lock A. It finds out that
its priority is higher than Thread 0, the holder of the lock. It donates
its priority to Thread 0, making it 40. Now Thread 0 is back again in
charge of the CPU. It sets its priority to 20, which was what it was
planning to do before Thread 1 came. TAH-DAH! Priority inversion has
occured.

To prevent this from happening we turned off the interrupt while during
thread_set_priority () call. We cannot use locks because, race
conditions happen due to locks. The same scenario mentioned above will
still happen. What is worse is the fact that now the problem may occur
even if Thread 0 was not holding any locks before calling the
thread_priority_set () function, since the function itself tries to
acquire a lock during its call.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

fixed-point.h:
/* define fixed-point, and its operators.
for 32 bit system, sign for 1 bit, 17 bit for num, 14 bit for float. */

typedef int fixed_point;

static inline fixed_point
fp (int n)
{
  return n * FIXED_POINT_F;
}

static inline int
fp_floor (fixed_point x)
{
  return x / FIXED_POINT_F;
}

static inline int
fp_round (fixed_point x)
{
  if (x >= 0)
    return (x + FIXED_POINT_F / 2) / FIXED_POINT_F;
  else
    return (x - FIXED_POINT_F / 2) / FIXED_POINT_F;
}

static inline fixed_point
fp_add (fixed_point x, fixed_point y)
{
  return x + y;
}

static inline fixed_point
fp_add_int (fixed_point x, int n)
{
  return x + n * FIXED_POINT_F;
}

static inline fixed_point
fp_subtract (fixed_point x, fixed_point y)
{
  return x - y;
}

static inline fixed_point
fp_subtract_int (fixed_point x, int n)
{
  return x - n * FIXED_POINT_F;
}


static inline fixed_point
fp_multiply (fixed_point x, fixed_point y)
thread.c :
static struct list thread_list; //list of every threads(status of BLOCKED, RUNNING, RADY)
static;
fixed_point load_avg;   //value of load_avg over system.  value is floating point.



thread.h :
struct thread {
  int nice;                     // thread's nice vaue(integer)
  fixed_point recent_cpu;       // thread's recent_cpu value(floating value)
  struct elem_list elem_;       // elem_list of thread for element of thread_list
}
---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  64  62  60     A
 4      4   0   0  63  62  60     A 
 8      8   0   0  62  62  60     A
12      12  0   0  61  62  60     B
16      12  4   0  61  61  60     B
20      12  8   0  61  60  60     A
24      16  8   0  60  60  60     A
28      20  8   0  59  60  60     C
32      20  8   4  59  60  59     B
36      20  12  4  59  59  59     B
    
>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
   
   It is ambiguity for OS to choose which thread to run at the time of thread_yield when two threads are same. Our decision is to use FIFO for same priorities in ready_list. And it matched with my scheduler.
   Moreover, when runing thread and reay thread have same priories, I choosed to run running thread in order to maintain FIFO.
  Finally, I choosed not to use thread_yield immediately when some thread from THREAD_BLOCK converts to THREAD_READY. However, final test mlfqs-block forced me to use thread_yield immediately especially just after lock_release.
>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
  When a function's time is more or equal than O(n), I used timerer interrupt. Hence, the priority or recent_cpu was not changed during searching for thread_list. Especially, I did not use timer interrupt when i implanted priority_yield function inside lock_release. (priority_level compares priority of running thread and front element of ready_list) When i use the function thread_yield, i avoided to use timer interrupt. because it is unable to enable timer_interrupt after thread_yield.
---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
  Advantage: i did not use too much intr_disable() hence our design avoids interrupt disable as much as we could.
  Disadvanage: We implanted new elem_list elem_ in the struct thread. so that there is ambitigy to make error when we try to use the size of struct thread. And also we did not make check to make thread_list empty when the process ends. So for load_avg.
  Finally, our fixed-point head file does not care about 64-bit representation system since we only take care of 32-bit system.
  If i had more timer, i would refine those disadvantages.
>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
