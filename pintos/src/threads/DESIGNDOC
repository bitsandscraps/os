			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jongeui Park <qkrwhddml@kaist.ac.kr>
Seongsu Cho  <csp00141@kaist.ac.kr>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

We have also completed the extra credit assignment on implementing
nested priority donation.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

At first we did not know that even the first part of the first
assignment will require us to make new data structures and functions. We
tried to find a way to manage it without creating new things, which we
failed, and googled for a solution. We found the following blog:
http://maplejune.tistory.com/entry/Pintos-프로젝트-1-Alarm-Clock
After finishing the first part by the help from the blog, we realized
that we should never be afraid of creating new things.
    For the second part we got some insights for our
implementation from
http://maplejune.tistory.com/entry/Pintos-프로젝트-1-Priority-Scheduling
and
http://ysocks.egloos.com/m/501047
We did not read thoroughly throughout the blogs, though. We just skimmed
their ideas and find out a new(hopefully better) way to implement.
    For the third part we referred to the following codes someone
uploaded on github:
https://github.com/yuwumichcn223/pintos

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

waiting_list is a list of processes that are sleeping.

static struct list waiting_list;

Added to struct thread:

    int64_t wakeup_tick;                /* Timer tick to wake up. */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When timer_sleep is called, the timer tick that it should wake up is
calculated. Storing that wakeup_tick information, the thread is moved to
the waiting_list. Then, thread_block() is called.
    The timer interrupt handler searches for threads that should be
awakened and unblocks those threads using thread_unblock().

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The waiting_list is always sorted in the order of wakeup_tick. If the
interrupt handler finds out that the current element on the list should
not yet be awakened, it may just end traversing the list.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We just disabled the interrupt. The kernel does not context switch
during the call to timer_sleep().

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We just disabled the interrupt. Timer interrupt cannot happen during
the call to timer_sleep().

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

To wake the threads without yielding to another thread, we must maintain
a list of threads that are sleeping. There are some design choices about
how to maintain this list. We chose to insert the threads in the
waiting_list in an ordered manner, so that we can reduce the number of
threads the kernel should inspect to wake them up. Other choice may be
to put them in arbitrary order(just push them front) and sort them every
tick. Since sorting is recursive and needs lot of memory we implemented
using list_insert_ordered ().

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int initial_priority;         /* Initial priority. */
    /* Lock that the thread is trying to acquire. */
    struct lock * lock_trying_acquire;
    struct list locks_holding;    /* Locks the thread is holding. */

Added to struct lock:

    int priority;                 /* Most recent priority donation. */
    struct list_elem elem;        /* List element. Managed in struct thread. */

Added to struct semaphore_elem:

    int priority;                 /* Priority of thread waiting. */


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Nested donation is done by recording the lock that the thread is waiting
for using the member lock_trying_acquire of struct thread. More detailed
description of the algorithm will be given as answers of questions B4
and B5. We attach a simple ASCII art describing the process of nested
donation. For simplicity, we will not consider multiple donations. For
the following drawings, L will denote the lock_trying_acquire member and
P the priority. The arrows starting from the L will be pointing at the
holder of the lock.

Step 1. Thread 0 of priority 30 is holding lock A. Thread 1 of priority
        40 is holding lock B.

        +--------------+         +--------------+
        |   Thread 0   |         |   Thread 1   |
        |   P = 30     |         |   P = 40     |
        |   L = NULL   |         |   L = NULL   |
        |   READY      |         |   RUNNING    |
        +--------------+         +--------------+

Step 2. Thread 1 tries to acquire Lock A.

        +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1   |
        |   P = 30     |    |    |   P = 40     |
        |   L = NULL   |    +----+-- L = A      |
        |   READY      |         |   RUNNING    |
        +--------------+         +--------------+

Step 3. Finding out that priority of Thread 0 is lower than priority of
        Thread 1, Thread 1 donates its priority to Thread 0.

        +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1   |
        |   P = 40     |    |    |   P = 40     |
        |   L = NULL   |    +----+-- L = A      |
        |   READY      |         |   RUNNING    |
        +--------------+         +--------------+

Step 4. Finding out that Thread 0 is not waiting for any lock Thread 1
        stops the donation and goes into blocking state.

        +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1   |
        |   P = 40     |    |    |   P = 40     |
        |   L = NULL   |    +----+-- L = A      |
        |   RUNNING    |         |   BLOCKED    |
        +--------------+         +--------------+

Step 5. Thread 2 of priority 50, is holding lock C.

        +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1   |         |   Thread 2   |
        |   P = 40     |    |    |   P = 40     |         |   P = 50     |
        |   L = NULL   |    +----+-- L = A      |         |   L = NULL   |
        |   READY      |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+

Step 6. Thread 2 tries to acquire lock B.

        +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2   |
        |   P = 40     |    |    |   P = 40     |    |    |   P = 50     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |
        |   READY      |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+

Step 7. Finding out that priority of Thread 1 is lower than priority of
        Thread 2, Thread 2 donates its priority to Thread 1.

        +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2   |
        |   P = 40     |    |    |   P = 50     |    |    |   P = 50     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |
        |   READY      |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+

Step 8. Finding out that Thread 1 is waiting for lock A, which is held
        by Thread 0. Thread 2 compares its priority with Thread 0. Since
        Thread 2's priority is higher, it donates its priority to
        Thread 0.

        +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2   |
        |   P = 50     |    |    |   P = 50     |    |    |   P = 50     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |
        |   READY      |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+

Step 9. Finding out that Thread 0 is not waiting for any lock Thread 2
        stops the donation and goes into blocking state.

        +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2   |
        |   P = 50     |    |    |   P = 50     |    |    |   P = 50     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |
        |   RUNNING    |         |   BLOCKED    |         |   BLOCKED    |
        +--------------+         +--------------+         +--------------+

Step 10. Thread 0 is sleeping for a while. Thread 3 is of priority 20.

        +--------------+         +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2   |         |   Thread 3   |
        |   P = 50     |    |    |   P = 50     |    |    |   P = 50     |         |   P = 20     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |         |   L = NULL   |
        |   BLOCKED    |         |   BLOCKED    |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+         +--------------+

Step 11. Thread 3 tries to acquire lock C.

        +--------------+         +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2 <-+----+    |   Thread 3   |
        |   P = 50     |    |    |   P = 50     |    |    |   P = 50     |    |    |   P = 20     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |    +----+-- L = C      |
        |   BLOCKED    |         |   BLOCKED    |         |   BLOCKED    |         |   RUNNING    |
        +--------------+         +--------------+         +--------------+         +--------------+

Step 12. Finding out that Thread 2 has higher priority than Thread 3
         Thread 3 just goes into block state without any kind of further
         action.

        +--------------+         +--------------+         +--------------+         +--------------+
        |   Thread 0 <-+----+    |   Thread 1 <-+----+    |   Thread 2 <-+----+    |   Thread 3   |
        |   P = 50     |    |    |   P = 50     |    |    |   P = 50     |    |    |   P = 20     |
        |   L = NULL   |    +----+-- L = A      |    +----+-- L = B      |    +----+-- L = C      |
        |   RUNNING    |         |   BLOCKED    |         |   BLOCKED    |         |   BLOCKED    |
        +--------------+         +--------------+         +--------------+         +--------------+

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The sema_up () function awakens the thread with the highest priority
using the list_max () function on its waiters list. To ensure that
that the running thread should always be the one with the highest
priority, the function compares the priority of the current thread
and the newly unblocked thread. If the new thread has higher priority
the current thread will yield to the new one.
    Since each lock uses a single semaphore, highest priority awakens
first rule is automatically applied to locks. For conditional variables,
though, this is not the case. Conditional variables assign different
semaphores to different threads. So we added a new element in struct
semaphore_elem to record the priority of the thread holding the
semaphore. When the cond_signal () is called, the semaphore with the
highest priority will be unblocked.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

An important point to remember is that a thread will never try to
acquire more than one lock at a time. This makes things a lot easier.
We added a new member in struct thread to remember what lock the thread
is trying to acquire. The actual and detailed processes is as following.
    Suppose Thread 0 of priority 20 holds lock A. Thread 1 of
priority 30 holding lock B tries to acquire lock A. It sets the
lock_trying_acquire to point at lock A. It sees that Thread 0, the
holder of lock A has lower priority than itself, so it donates its
priority to Thread 0, and Thread 0 now has priority 30.
    Now Thread 2 of priority 40 holding lock C tries to acquire lock B.
It sets its lock_trying_acquire to point at lock B. It sees that
Thread 1, the holder of lock B has lower priority than itself, so it
donates its priority to Thread 1, and Thread 1 now has priority 40. It
does not stop here, though. It sees if Thread 1 is waiting for any lock,
which it is. After knowing that Thread 1 is waiting for lock A, held by
Thread 0, it compares its priority with Thread 0, and finds out that
Thread 0 has lower priority than itself. So it donates its priority to
Thread 0 and priority of Thread 0 becomes 40. Seeing that Thread 0 is
not waiting for any locks, Thread 2 goes into blocked state.
    Now Thread 3 of priority 10 tries to acquire lock C(it is usually
impossible for a thread with lower priority to run, but it can when the
thread with higher priority is sleeping or waiting for some I/O). It
sets its lock_trying_acquire to point at lock C and finds out that it is
held by Thread 2. But Thread 2 has higher priority than itself, so
Thread 3 just goes into blocked state without taking any further
actions.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

To restore its original priority after releasing the lock, the thread
must remember its initial priority, so we added initial_priority to
struct thread. Looks quite simple. But there is more to it. This is
because of multiple donations. For example if Thread 0 of priority 30
is holding both locks A and B, and Thread 1 donates priority 40 via
lock A and Thread 2 donates priority 50 via lock B. If Thread 0 wants
to release lock A, it should not return to its initial priority, which
is 30, but rather to 50 since Thread 2 is still waiting for Thread 0 to
release lock B. To resolve this kind of problem we made the lock itself
to remember what kinds of priority donations have happened through
itself, and the thread to remember what kinds of locks it is holding.
We will explain how it works.
    Suppose Thread 0 of priority 30 is holding locks A, B, and C. As it
acquired the locks it has recorded its priority in the priority member
of each locks. Thread 1 of priority 40 tries to acquire lock A. It
donates its priority to Thread 0 and records it in member priority of
lock A. Thread 2 of priority 50 tries to acquire lock A. It donates its
priority to Thread 0 and records it in member priority of lock A.
Thread 3 of priority 20 tries to acquire lock A. It does not need to
donate, and the priority of lock A is unchanged. Thread 4 of priority
40 tries to acquire lock B. It does not need to donate, but since the
priority of the lock is less than the priority of the thread itself, it
sets the priority of the lock to be 40 and returns. Thread 5 of priority
50 tries to acquire lock C. It does not need to donate, but as Thread 4
did, it modifies the priority of lock C to be 50.
    Now Thread 0 releases lock A. It first sees if it is holding any
locks. It finds out that it is holding lock B of priority 40 and lock C
of priority 50. So it sets(in reality, the thread does not modify its
priority value) its priority to 50, the maximum value. Thread 0 then
releases lock C. It knows that it is holding lock B of priority 40, so
it changes its priority to 40 and yields to another thread. When
Thread 0 is scheduled again and releases lock B, it will then return to
its original priority, 30, since it does not hold locks any more.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Suppose Thread 0 with priority 30 is holding lock A. It is trying to set
its priority to be 20. Before the setting is finished, here comes
Thread 1 with priority 40. It tries to acquire lock A. It finds out that
its priority is higher than Thread 0, the holder of the lock. It donates
its priority to Thread 0, making it 40. Now Thread 0 is back again in
charge of the CPU. It sets its priority to 20, which was what it was
planning to do before Thread 1 came. WHAM! Priority inversion has
occurred.
    To prevent this from happening we turned off the interrupt while
during thread_set_priority () call. We cannot use locks because, race
conditions happen due to locks. The same scenario mentioned above will
still happen. What is worse is the fact that now the problem may occur
even if Thread 0 was not holding any locks before calling the
thread_priority_set () function, since the function itself tries to
acquire a lock during its call.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose not to implement using dynamic priority calculation because
it seemed little unintuitive and complicated to us. There are various
places in the kernel code where we need to access the priority
information of a thread, and it seemed too expensive to recalculate the
priority every time we need it.
    To implement nested donation, it is necessary to remember what locks
a thread is waiting for. We first thought about maintaining a list of
locks that each thread is waiting for, but soon found out that a thread
can wait for only one lock at a time. So we changed it to a pointer
variable, which makes things a lot simpler.
    To implement multiple donation, as discussed above, it is important
to remember what priority to restore after releasing, since we choose
not to use dynamic calculation. An option may be to record the history
of priority change in struct thread using an array or list. But it makes
it hard to distinguish nested donation from multiple donations. Since
they differ from each other by the fact that one happens through one
lock but the other by multiple locks, we tried to record the donated
priority in the lock and remember what locks the thread is holding.
    While writing this document, we found out some holes in our
implementation. First, we are not sure whether our pintos will service
round robbing for more than three threads. Our current implementation
uses list_insert_ordered () function in managing the ready threads in
the order of priority. The list_insert_ordered () function puts a
thread right before the first thread with priority less or equal to the
original thread. So if there are three threads with the same priority,
say Thread 0, 1, and 2, Thread 0 will run and Thread 1 and 2 will be in
the ready list. When Thread 0 is preempted, Thread 1 will be popped out
from the list and Thread 0 will be inserted right before Thread 2. When
Thread 1 is preempted, Thread 0 will pop out and Thread 1 will be
inserted in front of Thread 2. So Thread 2 will starve. We tried to
modify the less function of list_inserted_ordered () but it caused
a lot of bugs we could not fix on time.
    Second, for conditional variables the priority scheduling does not
work when the priority is changed while the thread is waiting. We tried
to record the thread itself in the struct semaphore_elem, but it also,
for an unidentified reason, caused lots of bugs we did not have enough
time to handle.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

all_list is the list of all processes. Threads are added to the list
during init_thread () and removed during thread_exit ().

static struct list all_list;

load_avg is the estimation of the average number of threads ready to
run over the past minute.

static fixed_point load_avg;

Defined fixed_point, which is actually int, in order to distinguish
it from an ordinary integer.

typedef int fixed_point;

Added in struct thread:

    /* Parameters for advanced scheduler */
    /* Integer value that determines how nice the thread should be to
     * other threads. */
    int nice;
    /* Metric of how much CPU time the thread has received recently. */
    fixed_point recent_cpu;
    /* Element in all_list of thread.c. */
    struct list_elem elem_all;          /* List element. */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  64  62  60     A
 4      4   0   0  63  62  60     A 
 8      8   0   0  62  62  60     A
12      12  0   0  61  62  60     B
16      12  4   0  61  61  60     B
20      12  8   0  61  60  60     A
24      16  8   0  60  60  60     A
28      20  8   0  59  60  60     C
32      20  8   4  59  60  59     B
36      20  12  4  59  59  59     B
    
>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
   
There is an ambiguity in choosing which thread to run when
thread_yield () is called if multiple threads have the same priority.
Our decision was to use the FIFO principle for threads with same
priority, which matches with our scheduler. Moreover, when running
thread and ready thread has same priorities, we choose to run running
thread in order to maintain the FIFO principle. At first, we tried not
to use thread_yield () immediately after some thread in BLOCKED state
is converted to READY state. However, the final test case(mlfqs-block)
forced us to use thread_yield (), at least after lock_release ().

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

When the algorithmic complexity of a function was greater or equal to
O(n), we used timerer interrupt to prevent other threads from calling
the same function again. Hence, the priority or recent_cpu is not
changed, traversing the all_list. But we did not use timer interrupt
when we implemented priority_yield (), a function that compares the
priority of the current thread with the first element of the ready_list
and yields if needed. This is because it might make every thread to
stop.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages of our design.

We tried as much as we could to implement the scheduler without turning
the interrupt off. This is because turning off the interrupt prevents
the priority from being recalculated, which will lead to wrong scheduler
behavior.

Disadvantages of our design.

We added a new list_elem in struct thread. We are slightly worried about
the size of struct thread. It might be too big and cause some problems
in the future. Also we did not check whether the all_list is empty
before exiting the process. So is for load_avg. Finally, our fixed-point
data structures and algorithms do not care about 64-bit representation
system. We only handle 32-bit systems. If extra time is given, we will
try to refine these drawbacks of our pintos.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We think that this implementation, using typedef and static inline
functions, is very simple but not so simplistic. We can distinguish
ordinary integers from our "fixed-point" type easily, and the static
inline-ness makes it really fast. We did not consider about using
macros, since many programmers say that they are evil(However, we used
them to define the q and f values of the fixed-point calculation
algorithm to make the code consistent with others). We might have
defined some kind of struct, may be consisting of two integers, the
integer part and the fraction part, but we thought this approach
was an overkill and will degrade the computation speed.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

We think that the assignment is quite challenging but doable. It took a
long time for us to finish, but we believe that most of the delays were
caused by our mistakes.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Reading the kernel code of pintos allowed us to clarify our vague
understanding of context switching that happens in the CPU. The
assignment also allowed us to get a grasp of how scheduler actually
works.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

We first misunderstood the definition of priority donation. We thought
that we had to donate the priority to all of the waiters. Suppose
Thread 0 with priority 30 has lock A, and Thread 1 and 2 both of
priority 30 is waiting for lock A. Now Thread 3 of priority 40 comes
and tries to acquire lock A. We originally thought that Thread 3 should
donate its priority to all of Thread 0, 1, and 2, which turned out to
be a totally wrong understanding of the specifications.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We think it would be helpful if there are more test cases. While writing
the DESIGNDOC, we found out some corner cases that our implementation
cannot handle. Regarding the fact that the implementation had passed all
27 tests, we are very sure that the test cases are not enough. Also we
are worried about the possibility that the bugs we were not able to find
in this assignment affecting the future assignments.

>> Any other comments?

We think it will be nicer for students, and really helpful to the TAS,
if we are allowed to write our DESIGNDOCs in WYSIWYG-like editors, such
as Hancom or Microsoft word. We really love vim and think that it is one
of the best editors for programming, but for writing reports? Well...
Readability of non-spacious articles is really poor in vim. We believe
that visual editors have their strength in those areas.

