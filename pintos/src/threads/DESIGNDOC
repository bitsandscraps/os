			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jongeui Park <qkrwhddml@kaist.ac.kr>
Seongsu Cho  <csp00141@kaist.ac.kr>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

At first we did not know that even the first assignment will require us
to make new data structures and functions. We tried to find a way to
manage it without creating new things, which we failed, and googled for
a solution. We found the following blog:
http://maplejune.tistory.com/entry/Pintos-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-1-Alarm-Clock
After finishing the first part by the help from the blog, we realized
that we should never be afraid of creating new things.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

waiting_list is a list of processes that are sleeping.

static struct list waiting_list;

Added to struct thread:

    int64_t wakeup_tick;                /* Timer tick to wake up. */

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When timer_sleep is called, the timer tick that it should wake up
is calculated. Storing that wakeup_tick information, the thread is
moved to the waiting_list. Then, thread_block() is called.

The timer interrupt handler searches for threads that should be
awakened and unblocks those threads using thread_unblock().

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The waiting_list is always sorted in the order of wakeup_tick.
If the interrupt handler finds out that the current element on the
list should not yet be awakened, it may just end traversing the list.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We just disabled the interrupt. The kernel does not context switch
during the call to timer_sleep().

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We just disabled the interrupt. Timer interrupt cannot happen during
the call to timer_sleep().

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:

    int initial_priority;         /* Initial priority. */
    /* Lock that the thread is trying to acquire. */
    struct lock * lock_trying_acquire;
    struct list locks_holding;    /* Locks the thread is holding. */

Added to struct lock:

    int priority;                 /* Most recent priority donation. */
    struct list_elem elem;        /* List element. Managed in struct thread. */

Added to struct semaphore_elem:

    int priority;                 /* Priority of thread waiting. */


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

The sema_up () function awakens the thread with the highest priority
using the list_max () function on its waiters list. To ensure that
that the running thread should always be the one with the highest
priority, the function compares the priority of the current thread
and the newly unblocked thread. If the new thread has higher priority
the current thread will yield to the new one.

Since each lock uses a single semaphore, highest priority awakens first
rule is automatically applied to locks. For conditional variables,
though, this is not the case. Conditional variables assign different
semaphores to different threads. So we added a new element in struct
semaphore_elem to record the priority of the thread holding the
semaphore. When the cond_signal () is called, the semaphore with the
highest priority will be unblocked.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

An important point to remember is that a thread will never try to
acquire more than one lock at a time. This makes things a lot easier.
We added a new member in struct thread to remember what lock the thread
is trying to acquire. The actual and detailed processes is as following.

Suppose Thread 0 of priority 20 holds lock A. Thread 1 of priority 30
holding lock B tries to acquire lock A. It sets the lock_trying_acquire
to point at lock A. It sees that Thread 0, the holder of lock A has
lower priority than itself, so it donates its priority to Thread 0, and
Thread 0 now has priority 30.

Now Thread 2 of priority 40 holding lock C tries to acquire lock B. It
sets its lock_trying_acquire to point at lock B. It sees that Thread 1,
the holder of lock B has lower priority than itself, so it donates its
priority to Thread 1, and Thread 1 now has priority 40. It does not
stop here, though. It sees if Thread 1 is waiting for any lock, which it
is. After knowing that Thread 1 is waiting for lock A, held by Thread 0,
it compares its priority with Thread 0, and finds out that Thread 0 has
lower priority than itself. So it donates its priority to Thread 0 and
priority of Thread 0 becomes 40. Seeing that Thread 0 is not waiting for
any locks, Thread 2 goes into blocked state.

Now Thread 3 of priority 10 tries to acquire lock C. It sets its
lock_trying_acquire to point at lock C and finds out that it is held by
Thread 2. But Thread 2 has higher priority than itself, so Thread 3 just
goes into blocked state without taking any further actions.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

To restore its original priority after releasing the lock, the thread
must remember its initial priority, so we added initial_priority to
struct thread. Looks quite simple. But there is more to it. This is
because of multiple donations. For example if Thread 0 of priority 30
is holding both locks A and B, and Thread 1 donates priority 40 via
lock A and Thread 2 donates priority 50 via lock B. If Thread 0 wants
to release lock A, it should not return to its initial priority, which
is 30, but rather to 50 since Thread 2 is still waiting for Thread 0 to
release lock B. To resolve this kind of problem we made the lock itself
to remember what kinds of priority donations have happened through
itself, and the thread to remember what kinds of locks it is holding.
We will explain how it works.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Suppose Thread 0 with priority 30 is holding lock A. It is trying to set
its priority to be 20. Before the setting is finished, here comes
Thread 1 with priority 40. It tries to acquire lock A. It finds out that
its priority is higher than Thread 0, the holder of the lock. It donates
its priority to Thread 0, making it 40. Now Thread 0 is back again in
charge of the CPU. It sets its priority to 20, which was what it was
planning to do before Thread 1 came. WHAM! Priority inversion has
occurred.

To prevent this from happening we turned off the interrupt while during
thread_set_priority () call. We cannot use locks because, race
conditions happen due to locks. The same scenario mentioned above will
still happen. What is worse is the fact that now the problem may occur
even if Thread 0 was not holding any locks before calling the
thread_priority_set () function, since the function itself tries to
acquire a lock during its call.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

all_list is the list of all processes. Threads are added to the list
during init_thread () and removed during thread_exit ().

static struct list all_list;

load_avg is the estimation of the average number of threads ready to
run over the past minute.

static fixed_point load_avg;

Defined fixed_point, which is actually int, in order to distinguish
it from an ordinary integer.

typedef int fixed_point;

Added in struct thread:

    /* Parameters for advanced scheduler */
    /* Integer value that determines how nice the thread should be to
     * other threads. */
    int nice;
    /* Metric of how much CPU time the thread has received recently. */
    fixed_point recent_cpu;
    /* Element in all_list of thread.c. */
    struct list_elem elem_all;          /* List element. */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  64  62  60     A
 4      4   0   0  63  62  60     A 
 8      8   0   0  62  62  60     A
12      12  0   0  61  62  60     B
16      12  4   0  61  61  60     B
20      12  8   0  61  60  60     A
24      16  8   0  60  60  60     A
28      20  8   0  59  60  60     C
32      20  8   4  59  60  59     B
36      20  12  4  59  59  59     B
    
>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
   
There is an ambiguity in choosing which thread to run when
thread_yield () is called if multiple threads have the same priority.
Our decision was to use the FIFO principle for threads with same
priority, i.e. we scheduled them according  in ready_list. And it matched with my scheduler.
   Moreover, when runing thread and reay thread have same priories, I choosed to run running thread in order to maintain FIFO.
  Finally, I choosed not to use thread_yield immediately when some thread from THREAD_BLOCK converts to THREAD_READY. However, final test mlfqs-block forced me to use thread_yield immediately especially just after lock_release.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

When the algorithmic complexity of a function was greater or equal to
O(n), we used timerer interrupt. Hence, the priority or recent_cpu
cannot be changed, for example, while traversing the all_list.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages of our design.

We tried as much as we could to implement the scheduler without turning
the interrupt off.

Disadvantages of our design.

We added a new list_elem in struct thread. so that there is ambitigy to make error when we try to use the size of struct thread. And also we did not make check to make thread_list empty when the process ends. So for load_avg.
  Finally, our fixed-point head file does not care about 64-bit representation system since we only take care of 32-bit system.
  If i had more timer, i would refine those disadvantages.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We think that this implementation, using typedef and static inline
functions, is very simple but not so simplistic. We can distinguish
ordinary integers from our "fixed-point" type easily, and the static
inline-ness makes it really fast. We did not consider about using
macros, since many programmers say that they are evil(However, we used
them to define the q and f values of the fixed-point calculation
algorithm to make the code consistent with others). We might have
defined some kind of struct, may be consisting of two integers, the
integer part and the fraction part, but we thought this approach
was an overkill.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
